# 201511

plan date: 20151106

summarize date：20151129

key word：`Spark` `Mongo` `algo` `hiredis`

##计划 
>* spark: 结合使用spark，熟悉常用transfromation和aciton
>* mllib: 源码分析
>* scala: 语言学习


##总结

###1. 工作方面
翻了下11月自己的周报，发现工作主要就是围绕着两件事情，刷单和IM。各自的变化就是刷单开始使用spark，IM开始接入店铺特征数据。

* 能够用scala编写spark程序，sbt提交任务到集群，run了一个图的例子。主要在于运用spark快速统计数据分析。
* IM接入店铺特征，主要就是在nginx中读取mongo的特征库数据，目前的特征库相对比较简单。上周五快下班发现nginx中读取mongo的数据出现不一致的情况，暂时还没有debug。


###2. 技术积累

这个月好像没怎么翻书本，都是在纠结工作上的事情，以前看过的spark开始用起来了。就几个关键词做个简单的总结如下

* spark：运用scala编写spark程序，sbt打包提交任务，整个流程通了。编写了若干个任务，用于统计数据分析
* nginx && redis：nginx中调用hiredis客户端，CLOSE_WAIT的debug，对网络高并发有了肤浅的任务
* redis本月没看啥。mongo读过一些博客
* leetcode刷了几题，何时刷完

###3. 个人思考
* 代码只是思想的表达: 编程(包括语言、大数据工具等)只是思想的表达，只有清楚了业务场景，有了足够清晰的思路和策略，再来实现，代码才能写得流畅。技术实现从来都不是最难的。想清楚再写代码，不然越写越乱
* 结合业务思考技术: 技术绝非是独立的，它都是这样被造出来(人们面临N多类似业务场景，抽象出公共的某种需求，造轮子满足大众需求)。比如spark适合大数据迭代；storm专长流失计算；kafka适合做消息队列。这些庞大的工具不仅仅需要会用，更多的是要弄清楚它们为何而生，对应的适用场景
* 技术不仅要有深度，也要有广度；有自己专长的地方，同时眼界要开阔
* 技术选型；架构设计；这两点太大，暂时谈不上什么，不断积累，希望以后能"泛泛而谈"
* 技术的学习：实践先行；理论补充

